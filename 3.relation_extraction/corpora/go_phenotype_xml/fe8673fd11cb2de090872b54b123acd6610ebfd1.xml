<?xml version="1.0" ?>
<document id="fe8673fd11cb2de090872b54b123acd6610ebfd1">
  <chunk id="fe8673fd11cb2de090872b54b123acd6610ebfd1.c0" text="The Utility of Data Transformation for Alignment, De Novo Assembly and Classification of Short Read Virus Sequences"/>
  <chunk id="fe8673fd11cb2de090872b54b123acd6610ebfd1.c1" text="Advances in DNA sequencing technology are facilitating genomic analyses of unprecedented scope and scale, widening the gap between our abilities to generate and fully exploit biological sequence data. Comparable analytical challenges are encountered in other data-intensive fields involving sequential data, such as signal processing, in which dimensionality reduction (i.e., compression) methods are routinely used to lessen the computational burden of analyses. In this work, we explored the application of dimensionality reduction methods to numerically represent high-throughput sequence data for three important biological applications of virus sequence data: reference-based mapping, short sequence classification and de novo assembly. Leveraging highly compressed sequence transformations to accelerate sequence comparison, our approach yielded comparable accuracy to existing approaches, further demonstrating its suitability for sequences originating from diverse virus populations. We assessed the application of our methodology using both synthetic and real viral pathogen sequences. Our results show that the use of highly compressed sequence approximations can provide accurate results, with analytical performance retained and even enhanced through appropriate dimensionality reduction of sequence data."/>
  <chunk id="fe8673fd11cb2de090872b54b123acd6610ebfd1.c2" text="Viruses 2019, 11, 394 3 of 22 longest common subsequence (LCS) [29] , and alignment approaches, such as the Needleman-Wunsch and Smith-Waterman algorithms. Euclidean distance is arguably the most widely used Lp-norm method for sequential data comparison but can only be used on sequences of the same length. Furthermore, Lp-norm methods do not accommodate shifts in the x-axis (time or position) and are thus limited in their ability to identify similar features within offset data. Elastic similarity/dissimilarity methods, such as LCS, unbounded DTW and various alignment algorithms, permit comparison of data with different dimensions and tolerate shifts in the x-axis. These properties of elastic similarity methods can be very useful in the analysis of speech signals, for example, but can be computationally expensive [30] . Several approaches have been proposed to permit fast searching with DTW, including the introduction of global constraints (wrapping path) or the use of lower bounding techniques, such as LB_keogh [28] .">
    <entity charOffset="386-394" id="fe8673fd11cb2de090872b54b123acd6610ebfd1.c2.e0" ontology_id="HP_0012830" text="position" type="phenotype"/>
    <entity charOffset="879-883" id="fe8673fd11cb2de090872b54b123acd6610ebfd1.c2.e1" ontology_id="GO_0033867" text="fast" type="gene_function"/>
    <pair e1="fe8673fd11cb2de090872b54b123acd6610ebfd1.c2.e0" e2="fe8673fd11cb2de090872b54b123acd6610ebfd1.c2.e1" id="fe8673fd11cb2de090872b54b123acd6610ebfd1.c2.p0" relation="true"/>
  </chunk>
  <chunk id="fe8673fd11cb2de090872b54b123acd6610ebfd1.c3" text="While pairwise comparison methods may be used for clustering, classification and similarity searches, they are very time consuming for large datasets (O(n 2 ) time complexity). Indexing structures, such as the R*-tree, KD-tree, VP-tree and MVP-tree have significantly lower time complexity (O(n log(n))) for similarity search [31] and are more appropriate for efficient analysis of large datasets. The R*-tree [32, 33] and KD-tree [34] indexing structures are very accurate for low dimensional datasets. However, their performance deteriorates significantly in high dimensional space [31], a phenomenon known as the 'curse of dimensionality' [35, 36] . Metric trees, such as the VP-tree [37] and MVP-tree [38], are less prone to this limitation. Metric space indexing structures make use of geometric properties for partitioning data and work efficiently on both low and high dimensional data [39] . The curse of dimensionality can be further mitigated using data approximations, such as the DFT, the DWT and the PAA, to partition a dataset in an approximated space without loss of generality [21] ."/>
  <chunk id="fe8673fd11cb2de090872b54b123acd6610ebfd1.c4" text="Here, we investigate the performance of three established dimensionality reduction techniques on three common analysis tasks involving viral short read sequence data: classification, reference-based mapping/alignment and de novo assembly. We benchmarked the accuracy of our proposed methodology against existing tools, and demonstrate the applicability of time series and signal processing data mining techniques for the analysis of viral NGS data."/>
</document>
